# Mock AI Service - Генератор тестовых метрик

Этот сервис создан для демонстрации метрик в Grafana без необходимости запуска полного AI-сервиса с моделями.

## Что он делает

Mock-сервис генерирует реалистичные метрики для следующих показателей:

- **Запросы по агентам и статусам** - распределение запросов по различным агентам (Сеть, Приложение, Оборудование, и т.д.) и их статусам (success, error, escalated)
- **Время обработки запросов** - гистограммы времени отклика для разных агентов
- **Использование токенов** - метрики по использованию токенов (prompt, context, history, total)
- **Схожесть с агентами** - показатели схожести запросов с выбранными агентами
- **Схожесть контекста** - метрики схожести ответов с контекстом
- **Специальные случаи** - счетчики для приветствий, ненормативной лексики, эскалаций и т.д.
- **Активные чаты** - динамическое количество активных чатов (меняется в зависимости от времени суток)
- **Обрезки истории** - счетчик случаев обрезки истории чата

## Быстрый старт

### Вариант 1: Запуск только mock-сервиса с Grafana (рекомендуется)

```bash
cd backend
docker-compose -f docker-compose-mock.yml up
```

### Вариант 2: Локальный запуск (для разработки)

```bash
cd backend/ai-service
pip install -r requirements-mock.txt
python mock_metrics.py
```

## Доступ к интерфейсам

После запуска контейнеров:

- **Grafana**: http://localhost:3000
  - Логин: `admin`
  - Пароль: `admin`

- **Prometheus**: http://localhost:9090
  - Метрики доступны по адресу: http://localhost:9090/targets

- **Метрики mock-сервиса**: http://localhost:1234/metrics
  - Прямой доступ к метрикам в формате Prometheus

## Просмотр дашборда в Grafana

1. Откройте Grafana по адресу http://localhost:3000
2. Войдите с логином `admin` и паролем `admin`
3. Перейдите в раздел "Dashboards" → "Browse"
4. Выберите дашборд "Статистика AI-сервиса поддержки"

Вы увидите:
- Графики скорости обработки запросов
- Общее количество обработанных запросов
- Распределение запросов по агентам (pie chart)
- Распределение по статусам (pie chart)
- Специальные случаи (donut chart)
- Время обработки запросов (P50, P95)
- Использование токенов
- Схожесть запроса с агентом
- Средняя схожесть ответа с контекстом
- Статистика успешных запросов, эскалаций и ошибок

## Настройка частоты генерации метрик

По умолчанию mock-сервис генерирует ~30 запросов в минуту. Вы можете изменить это значение в файле `mock_metrics.py`:

```python
# В конце файла
if __name__ == "__main__":
    run_mock_service(port=1234, requests_per_minute=30)  # Измените здесь
```

Или передать параметр через переменную окружения (требуется изменение кода):

```yaml
environment:
  REQUESTS_PER_MINUTE: 60
```

## Структура метрик

### Счетчики (Counters)
- `ai_requests_total{agent, status}` - общее количество запросов
- `ai_special_cases_total{case_type}` - специальные случаи
- `ai_history_truncation_total` - обрезки истории

### Гистограммы (Histograms)
- `ai_request_duration_seconds{agent}` - время обработки
- `ai_tokens_used{token_type}` - использование токенов
- `ai_agent_selection_similarity{agent}` - схожесть с агентом
- `ai_context_similarity` - схожесть контекста

### Показатели (Gauges)
- `ai_active_chats` - количество активных чатов

## Остановка сервисов

```bash
docker-compose -f docker-compose-mock.yml down
```

## Переход к реальному AI-сервису

Когда будете готовы использовать настоящий AI-сервис:

1. Остановите mock-версию:
   ```bash
   docker-compose -f docker-compose-mock.yml down
   ```

2. Запустите полный стек с реальным AI-сервисом:
   ```bash
   docker-compose up
   ```

Метрики в Grafana будут автоматически переключены на реальные данные от AI-сервиса.

## Troubleshooting

### Метрики не отображаются в Grafana

1. Проверьте, что Prometheus собирает метрики:
   - Откройте http://localhost:9090/targets
   - Убедитесь, что target `ai-service` имеет статус "UP"

2. Проверьте, что mock-сервис работает:
   ```bash
   curl http://localhost:1234/metrics
   ```

3. Перезапустите сервисы:
   ```bash
   docker-compose -f docker-compose-mock.yml restart
   ```

### Дашборд пустой

- Подождите 1-2 минуты после запуска для накопления метрик
- Проверьте временной диапазон в Grafana (правый верхний угол) - убедитесь, что выбран "Last 1 hour" или подобный

### Контейнер ai-service падает

- Проверьте логи:
  ```bash
  docker-compose -f docker-compose-mock.yml logs ai-service
  ```

## Технические детали

Mock-сервис написан на Python и использует:
- `prometheus_client` для экспорта метрик
- Реалистичное распределение данных с использованием нормального распределения
- Различные веса для агентов и статусов, чтобы имитировать реальное использование
- Динамическое изменение количества активных чатов в зависимости от времени суток
