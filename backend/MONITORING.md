# Мониторинг и логирование AI-сервиса поддержки

## Обзор

Система мониторинга настроена для отслеживания эффективности AI-агентов и демонстрации того, как ИИ ускоряет работу с обращениями, повышает качество ответов и снижает нагрузку на сотрудников поддержки.

## Компоненты

### 1. AI-Service (порт 1234)
- **Экспорт метрик Prometheus** на порту 1234
- **Структурированное JSON логирование** для Loki
- Метрики включают:
  - Количество обработанных запросов по агентам и статусам
  - Время обработки запросов
  - Использование токенов
  - Схожесть с агентами и контекстом
  - Специальные случаи (эскалация, приветствия, ненормативная лексика)

### 2. Prometheus (порт 9090)
- Собирает метрики с ai-service каждые 10 секунд
- Хранит исторические данные
- URL: http://localhost:9090

### 3. Loki (порт 3100)
- Собирает и хранит логи из Docker контейнеров
- JSON логи автоматически парсятся Promtail
- URL: http://localhost:3100

### 4. Promtail (порт 9080)
- Агент для сбора логов из Docker контейнеров
- Автоматически парсит JSON логи ai-service
- Извлекает метаданные: chat_id, agent, username, duration, status

### 5. Grafana (порт 3000)
- Визуализация метрик и логов
- URL: http://localhost:3000
- Логин: **admin**
- Пароль: **admin**

## Дашборд "Статистика AI-сервиса поддержки"

После запуска системы дашборд автоматически доступен в Grafana.

### Основные панели:

1. **Скорость обработки запросов** - показывает RPS по агентам и статусам
2. **Всего обработано запросов** - общий счетчик
3. **Распределение запросов по агентам** - pie chart (Сеть, Приложение, Оборудование, и т.д.)
4. **Распределение по статусам** - успешно, передано специалисту, ошибки
5. **Специальные случаи** - приветствия, эскалация, отсутствие контекста
6. **Время обработки запросов (P50, P95)** - перцентили по агентам
7. **Использование токенов (P95)** - расход токенов по типам
8. **Схожесть запроса с агентом** - насколько точно выбран агент
9. **Средняя схожесть ответа с контекстом** - качество ответов
10. **Логи AI-сервиса** - структурированные логи в реальном времени

### Статистические панели внизу дашборда:
- Успешных запросов в минуту
- Передано специалисту в минуту
- Ошибок в минуту
- Обрезок истории в минуту

## Доступные метрики

### ai_requests_total
Общее количество обработанных запросов с метками:
- `agent`: название агента (Сеть, Приложение, Оборудование, и т.д.)
- `status`: статус обработки (success, escalated, error, greeting, profanity, etc.)

### ai_request_duration_seconds
Гистограмма времени обработки запросов с меткой `agent`

### ai_tokens_used
Гистограмма использования токенов с меткой:
- `token_type`: тип токенов (question, history, context, total)

### ai_agent_selection_similarity
Гистограмма схожести запроса с выбранным агентом

### ai_context_similarity
Гистограмма схожести ответа с контекстом

### ai_special_cases_total
Счетчик специальных случаев с меткой:
- `case_type`: тип случая (greeting, profanity, escalation, no_context, low_similarity)

### ai_history_truncation_total
Счетчик случаев обрезки истории сообщений

## Запуск системы

```bash
cd backend
docker-compose up -d
```

## Проверка работы

1. Откройте Grafana: http://localhost:3000
2. Войдите (admin/admin)
3. Перейдите в Dashboards → "Статистика AI-сервиса поддержки"
4. Отправьте несколько тестовых запросов через виджет
5. Наблюдайте обновление метрик в реальном времени (автообновление каждые 10 секунд)

## Примеры запросов для демонстрации

Для демонстрации эффективности AI отправьте различные типы запросов:

1. **Технические вопросы**: "Не работает интернет" → агент "Сеть"
2. **Вопросы о приложении**: "Как войти в систему?" → агент "Приложение"
3. **Приветствия**: "Привет" → специальный случай greeting
4. **Эскалация**: "Передай запрос специалисту" → escalated
5. **Неизвестный вопрос**: "Погода в Москве" → no_context

## Ключевые показатели для презентации

1. **Процент автоматизации**: (успешные + приветствия) / всего запросов * 100%
2. **Скорость ответа**: медианное время обработки (P50)
3. **Качество ответов**: средняя схожесть с контекстом (>0.7 = хорошо)
4. **Нагрузка на специалистов**: количество эскалированных запросов
5. **Эффективность агентов**: распределение по агентам показывает специализацию

## Структура файлов

```
backend/
├── ai-service/
│   ├── model.py                    # Основной код с метриками
│   ├── metrics.py                  # Определения метрик Prometheus
│   └── requirements.txt            # Добавлены prometheus_client и python-json-logger
├── grafana/
│   ├── datasources.yml             # Источники данных (Prometheus, Loki)
│   ├── dashboards.yml              # Конфигурация автозагрузки дашбордов
│   └── dashboards/
│       └── ai-service-dashboard.json  # Дашборд статистики
├── prometheus.yml                  # Конфигурация Prometheus
├── loki-config.yml                 # Конфигурация Loki
├── promtail-config.yml             # Конфигурация Promtail с JSON парсингом
└── docker-compose.yml              # Обновлен для всех сервисов
```

## Troubleshooting

### Метрики не отображаются
- Проверьте, что ai-service запущен: `docker ps | grep ai-service`
- Проверьте доступность метрик: `curl http://localhost:1234/metrics`
- Проверьте Prometheus targets: http://localhost:9090/targets

### Логи не появляются
- Проверьте, что Promtail работает: `docker logs promtail`
- Проверьте Loki: `docker logs loki`
- Убедитесь, что ai-service пишет JSON логи: `docker logs ai-service`

### Дашборд не загрузился
- Перезапустите Grafana: `docker-compose restart grafana`
- Проверьте логи: `docker logs grafana`
- Проверьте, что файлы дашборда примонтированы корректно

## Дополнительные возможности

### Кастомные запросы в Prometheus
Примеры PromQL запросов:

```promql
# Процент успешных запросов
sum(rate(ai_requests_total{status="success"}[5m])) / sum(rate(ai_requests_total[5m])) * 100

# Топ агентов по количеству запросов
topk(3, sum by (agent) (rate(ai_requests_total[5m])))

# Средняя скорость обработки по агентам
avg(rate(ai_request_duration_seconds_sum[5m]) / rate(ai_request_duration_seconds_count[5m])) by (agent)
```

### Алерты (опционально)
Можно настроить алерты в Prometheus для:
- Высокого процента эскалации (>30%)
- Долгого времени обработки (>5 секунд)
- Большого количества ошибок

## Заключение

Система мониторинга демонстрирует:
✅ Скорость работы AI-агентов
✅ Качество ответов через схожесть с контекстом
✅ Снижение нагрузки на специалистов через автоматизацию
✅ Специализацию агентов по типам запросов
✅ Прозрачность работы системы через детальные логи
