# –î–∏–∞–≥—Ä–∞–º–º–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã

## üìê –û–±–∑–æ—Ä –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã

–î–∞–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Å RAG (Retrieval-Augmented Generation).

---

## üéØ –ö–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

### 1. –û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä (Orchestrator)

**–§–∞–π–ª:** `backend/ai-service/model.py` ‚Üí —Ñ—É–Ω–∫—Ü–∏—è `process_query()`

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ:**
- –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ AI-—Å–∏—Å—Ç–µ–º—ã
- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Ç–æ–∫–æ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
- –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –≤—ã–±–æ—Ä–∞ –∞–≥–µ–Ω—Ç–æ–≤, RAG pipeline –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤

**–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:**
```python
def process_query(
    query: str,                          # –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    message_history: List[Dict] = None,  # –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞
    current_username: str = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å",
    chat_id: str = None
) -> Tuple[str, List[Dict]]:
```

**–û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:**

1. **–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞**
   - –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç—ã–µ –∑–∞–ø—Ä–æ—Å—ã
   - –î–µ—Ç–µ–∫—Ü–∏—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö –∫–æ–º–∞–Ω–¥ ("–ü–µ—Ä–µ–¥–∞–π —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É")
   - –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–µ–Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–π –ª–µ–∫—Å–∏–∫–∏

2. **–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞**
   - –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è –∏ –æ–±—â–∏–µ —Ñ—Ä–∞–∑—ã (similarity ‚â• 0.7)
   - –í—ã–±–æ—Ä –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ –∞–≥–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ embedding similarity
   - Fallback –Ω–∞ –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—â–µ–Ω–∏—è

3. **–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º**
   - –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ (–≤–æ–ø—Ä–æ—Å + –∏—Å—Ç–æ—Ä–∏—è + –∫–æ–Ω—Ç–µ–∫—Å—Ç)
   - –û–±—Ä–µ–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ –ª–∏–º–∏—Ç–∞
   - –†–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (150 tokens)

4. **–ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏**
   - –ó–∞–≥—Ä—É–∑–∫–∞ LoRA –∞–¥–∞–ø—Ç–µ—Ä–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
   - –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
   - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏ –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞

5. **–ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞**
   - –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (similarity —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º ‚â• 0.5)
   - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —ç—Å–∫–∞–ª–∞—Ü–∏—è –ø—Ä–∏ –Ω–∏–∑–∫–æ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
   - –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ –æ—Ç–≤–µ—Ç–∞

**–î–∏–∞–≥—Ä–∞–º–º–∞ –ø–æ—Ç–æ–∫–∞:**

```mermaid
graph TB
    START[–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞] --> CHECK_EMPTY{–ü—É—Å—Ç–æ–π?}
    CHECK_EMPTY -->|–î–∞| RETURN_ERROR[–í–æ–∑–≤—Ä–∞—Ç –æ—à–∏–±–∫–∏]
    CHECK_EMPTY -->|–ù–µ—Ç| CHECK_ESCALATION{–ö–æ–º–∞–Ω–¥–∞<br/>'–ü–µ—Ä–µ–¥–∞–π —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É'?}

    CHECK_ESCALATION -->|–î–∞| ESCALATE[isManager = true]
    CHECK_ESCALATION -->|–ù–µ—Ç| CHECK_PROFANITY{–ù–µ–Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è<br/>–ª–µ–∫—Å–∏–∫–∞?}

    CHECK_PROFANITY -->|–î–∞| WARN[–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ]
    CHECK_PROFANITY -->|–ù–µ—Ç| CHECK_GREETING{–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ?<br/>sim ‚â• 0.7}

    CHECK_GREETING -->|–î–∞| BASE_MODEL[–ì–µ–Ω–µ—Ä–∞—Ü–∏—è<br/>–±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª—å—é]
    CHECK_GREETING -->|–ù–µ—Ç| SELECT_AGENT[–í—ã–±–æ—Ä –∞–≥–µ–Ω—Ç–∞]

    SELECT_AGENT --> AGENT_FOUND{–ê–≥–µ–Ω—Ç –Ω–∞–π–¥–µ–Ω?<br/>sim ‚â• 0.25}
    AGENT_FOUND -->|–ù–µ—Ç| NOT_UNDERSTOOD[–ù–µ –ø–æ–Ω—è–ª –≤–æ–ø—Ä–æ—Å]
    AGENT_FOUND -->|–î–∞| RAG_SEARCH[RAG –ø–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞]

    RAG_SEARCH --> CONTEXT_FOUND{–ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞–π–¥–µ–Ω?<br/>sim ‚â• 0.25}
    CONTEXT_FOUND -->|–ù–µ—Ç| NOT_UNDERSTOOD
    CONTEXT_FOUND -->|–î–∞| MANAGE_TOKENS[–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞–º–∏]

    MANAGE_TOKENS --> TRIM_HISTORY{–ü—Ä–µ–≤—ã—à–µ–Ω<br/>–ª–∏–º–∏—Ç?}
    TRIM_HISTORY -->|–î–∞| CUT_HISTORY[–û–±—Ä–µ–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏]
    CUT_HISTORY --> TRIM_HISTORY
    TRIM_HISTORY -->|–ù–µ—Ç| GENERATE[–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å LoRA]

    GENERATE --> VALIDATE{Similarity —Å<br/>–∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º ‚â• 0.5?}
    VALIDATE -->|–ù–µ—Ç| ESCALATE
    VALIDATE -->|–î–∞| EXTRACT[–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ<br/>–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è]

    EXTRACT --> RETURN[–í–æ–∑–≤—Ä–∞—Ç –æ—Ç–≤–µ—Ç–∞]
    BASE_MODEL --> RETURN
    ESCALATE --> RETURN
    WARN --> RETURN
    NOT_UNDERSTOOD --> RETURN

    style START fill:#4CAF50,color:#fff
    style SELECT_AGENT fill:#2196F3,color:#fff
    style RAG_SEARCH fill:#FF9800,color:#fff
    style GENERATE fill:#9C27B0,color:#fff
    style RETURN fill:#4CAF50,color:#fff
```

---

### 2. –ê–≥–µ–Ω—Ç-—Å–µ–ª–µ–∫—Ç–æ—Ä (Agent Selector)

**–ö–ª–∞—Å—Å:** `ParagraphRetriever.select_agent()`

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ:**
- –í—ã–±–æ—Ä –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç embedding-based similarity matching

**–ê–ª–≥–æ—Ä–∏—Ç–º:**

```python
def select_agent(self, query: str) -> Tuple[Tokenizer, Model, str]:
    # 1. –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞
    query_emb = embedding_model.encode(query, prompt_name="paraphrase")

    # 2. –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–≤
    agent_names = ["–°–µ—Ç—å", "–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ", "–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ",
                   "–î–æ—Å—Ç—É–ø –∏ –ø–∞—Ä–æ–ª–∏", "–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å"]
    agent_embs = embedding_model.encode(agent_names, prompt_name="paraphrase")

    # 3. –í—ã—á–∏—Å–ª–µ–Ω–∏–µ cosine similarity
    similarities = cosine_similarity([query_emb], agent_embs)[0]

    # 4. –í—ã–±–æ—Ä –∞–≥–µ–Ω—Ç–∞ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º —Å—Ö–æ–¥—Å—Ç–≤–æ–º
    max_idx = similarities.argmax()
    max_sim = similarities[max_idx]

    # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ä–æ–≥–∞
    if max_sim < 0.25:
        return None, None, None  # –ê–≥–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω

    selected_agent = agent_names[max_idx]
    return agent_tokenizer, agent_model, knowledge_base_file
```

**–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã:**

| –ê–≥–µ–Ω—Ç | –û–±–ª–∞—Å—Ç—å | LoRA –∞–¥–∞–ø—Ç–µ—Ä | –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π |
|-------|---------|--------------|-------------|
| üåê **–°–µ—Ç—å** | –°–µ—Ç–µ–≤—ã–µ –ø—Ä–æ–±–ª–µ–º—ã, Wi-Fi, –∏–Ω—Ç–µ—Ä–Ω–µ—Ç | `–°–µ—Ç—å/best_model/` | `–°–µ—Ç—å.txt` |
| üíª **–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ** | –ü–û, Office, –±—Ä–∞—É–∑–µ—Ä—ã | `–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ/best_model/` | `–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.txt` |
| üîß **–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ** | –ü—Ä–∏–Ω—Ç–µ—Ä—ã, –∫–æ–º–ø—å—é—Ç–µ—Ä—ã, –ø–µ—Ä–∏—Ñ–µ—Ä–∏—è | `–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ/best_model/` | `–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ.txt` |
| üîë **–î–æ—Å—Ç—É–ø –∏ –ø–∞—Ä–æ–ª–∏** | –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è, –ø–∞—Ä–æ–ª–∏, –¥–æ—Å—Ç—É–ø | `–î–æ—Å—Ç—É–ø –∏ –ø–∞—Ä–æ–ª–∏/best_model/` | `–î–æ—Å—Ç—É–ø –∏ –ø–∞—Ä–æ–ª–∏.txt` |
| üõ°Ô∏è **–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å** | –í–∏—Ä—É—Å—ã, —Ñ–∏—à–∏–Ω–≥, –∑–∞—â–∏—Ç–∞ –¥–∞–Ω–Ω—ã—Ö | `–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å/best_model/` | `–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å.txt` |

**–ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã:**

```python
# –ó–∞–ø—Ä–æ—Å: "–ö–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å Wi-Fi?"
query_emb = [0.23, -0.45, 0.67, ...]  # 384-–º–µ—Ä–Ω—ã–π –≤–µ–∫—Ç–æ—Ä

# Embedding –∞–≥–µ–Ω—Ç–æ–≤
agent_embs = [
    [0.25, -0.42, 0.70, ...],  # –°–µ—Ç—å
    [0.10, -0.15, 0.05, ...],  # –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    [0.05, -0.08, 0.12, ...],  # –û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ
    [0.02, -0.03, 0.01, ...],  # –î–æ—Å—Ç—É–ø
    [0.01, -0.02, 0.03, ...]   # –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
]

# Cosine similarity
similarities = [0.92, 0.35, 0.28, 0.15, 0.12]

# –í—ã–±—Ä–∞–Ω: –°–µ—Ç—å (similarity = 0.92)
```

---

### 3. RAG Pipeline (Retrieval-Augmented Generation)

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**

#### 3.1. Paragraph Retriever

**–ö–ª–∞—Å—Å:** `ParagraphRetriever` (–Ω–∞—Å–ª–µ–¥—É–µ—Ç `BaseRetriever` –∏–∑ LangChain)

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ:**
- –ü–æ–∏—Å–∫ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
- –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ embeddings –≤ ChromaDB

**–ú–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞:**

```python
def _get_relevant_documents(self, query: str) -> List[Document]:
    # 1. –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞
    query_emb = embedding_model.encode(
        query,
        prompt_name="search_query",
        normalize_embeddings=True
    )

    # 2. –ü–æ–∏—Å–∫ –ø–æ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–º—É —Å—Ö–æ–¥—Å—Ç–≤—É
    paragraph_embs = self.paragraph_embeddings[current_agent]
    similarities = cosine_similarity([query_emb], paragraph_embs)[0]

    # 3. –í—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞
    max_idx = similarities.argmax()
    max_sim = similarities[max_idx]

    # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ä–æ–≥–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
    if max_sim < 0.25:
        return [Document(page_content="–ù–µ –ø–æ–Ω—è–ª –≤–æ–ø—Ä–æ—Å, —É—Ç–æ—á–Ω–∏—Ç–µ!")]

    best_paragraph = self.paragraphs[current_agent][max_idx]
    return [Document(page_content=best_paragraph)]
```

#### 3.2. Embedding Model

**–ú–æ–¥–µ–ª—å:** `sentence-transformers/frida` (–∑–∞–≥—Ä—É–∂–µ–Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ)

**–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:**
- –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: 384
- –¢–∏–ø: Sentence-BERT
- –ü—Ä–æ–º–ø—Ç—ã: `search_query`, `search_document`, `paraphrase`

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**

```python
# –î–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
query_emb = emb_model.encode(query, prompt_name="search_query")

# –î–ª—è –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
doc_emb = emb_model.encode(paragraph, prompt_name="search_document")

# –î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ñ—Ä–∞–∑ (–ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è, —ç—Å–∫–∞–ª–∞—Ü–∏—è)
phrase_emb = emb_model.encode(phrase, prompt_name="paraphrase")
```

#### 3.3. –•—Ä–∞–Ω–∏–ª–∏—â–µ –∑–Ω–∞–Ω–∏–π (ChromaDB)

**–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä:** `chromadb:8000`

**–ö–æ–ª–ª–µ–∫—Ü–∏—è:** `paragraph_embeddings`

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:**

```python
{
    "ids": ["–°–µ—Ç—å_0", "–°–µ—Ç—å_1", ..., "–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å_N"],
    "embeddings": [[0.23, -0.45, ...], [0.12, -0.33, ...], ...],
    "documents": ["–ü–∞—Ä–∞–≥—Ä–∞—Ñ 1", "–ü–∞—Ä–∞–≥—Ä–∞—Ñ 2", ...],
    "metadatas": [{"agent": "–°–µ—Ç—å"}, {"agent": "–°–µ—Ç—å"}, ...]
}
```

**–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö:**

```python
def load_all_paragraphs(self):
    for agent, config in agent_map.items():
        # –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
        with open(config["file_path"], "r", encoding="utf-8") as f:
            text = f.read()

        # –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
        paragraphs = split_into_paragraphs(text)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞ –≤ ChromaDB
        existing_ids = collection.get(where={"agent": agent})["ids"]

        if not existing_ids:
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ embeddings
            embeddings = emb_model.encode(
                paragraphs,
                prompt_name="search_document"
            )

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ ChromaDB
            for i, (para, emb) in enumerate(zip(paragraphs, embeddings)):
                collection.add(
                    documents=[para],
                    embeddings=[emb.tolist()],
                    ids=[f"{agent}_{i}"],
                    metadatas=[{"agent": agent}]
                )
        else:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ ChromaDB
            results = collection.get(where={"agent": agent})
            self.paragraphs[agent] = results["documents"]
            self.paragraph_embeddings[agent] = np.array(results["embeddings"])
```

**–î–∏–∞–≥—Ä–∞–º–º–∞ RAG Pipeline:**

```mermaid
graph LR
    QUERY[–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è] --> EMB_QUERY[–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞]

    KB[–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π<br/>5x txt —Ñ–∞–π–ª–æ–≤] --> SPLIT[–†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã]
    SPLIT --> EMB_DOCS[–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è<br/>–ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤]
    EMB_DOCS --> CACHE{–ö—ç—à –≤<br/>ChromaDB?}
    CACHE -->|–ù–µ—Ç| STORE[–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ ChromaDB]
    CACHE -->|–î–∞| LOAD[–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ ChromaDB]

    EMB_QUERY --> SIMILARITY[Cosine Similarity]
    STORE --> SIMILARITY
    LOAD --> SIMILARITY

    SIMILARITY --> TOP_K[–í—ã–±–æ—Ä top-1 –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞]
    TOP_K --> THRESHOLD{Similarity<br/>‚â• 0.25?}
    THRESHOLD -->|–ù–µ—Ç| FALLBACK[–ù–µ –ø–æ–Ω—è–ª –≤–æ–ø—Ä–æ—Å]
    THRESHOLD -->|–î–∞| CONTEXT[–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏]

    style EMB_QUERY fill:#2196F3,color:#fff
    style SIMILARITY fill:#FF9800,color:#fff
    style CONTEXT fill:#4CAF50,color:#fff
```

---

### 4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ (Generation Layer)

#### 4.1. –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å (LLM)

**–ú–æ–¥–µ–ª—å:** Qwen2-7B (–∫–≤–∞–Ω—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è)

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏:**
```json
{
  "model_type": "qwen2",
  "num_parameters": "7B",
  "num_hidden_layers": 28,
  "hidden_size": 3584,
  "num_attention_heads": 28,
  "vocab_size": 151665,
  "max_position_embeddings": 32768,
  "quantization": {
    "method": "bitsandbytes",
    "bits": 4,
    "type": "nf4",
    "compute_dtype": "float16"
  }
}
```

**–ü–∞–º—è—Ç—å:**
- –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å: ~14GB
- –ö–≤–∞–Ω—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è (4-bit): ~4-5GB VRAM

#### 4.2. LoRA –∞–¥–∞–ø—Ç–µ—Ä—ã

**–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:**
```python
lora_config = LoraConfig(
    task_type=TaskType.CAUSAL_LM,
    r=64,                    # –†–∞–Ω–≥ –º–∞—Ç—Ä–∏—Ü LoRA
    lora_alpha=128,          # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
    lora_dropout=0.1,        # Dropout –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj"]
)
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**
- –û–±—É—á–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞ –∞–¥–∞–ø—Ç–µ—Ä: ~33M (vs 7B –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏)
- –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ: 0.47% –æ—Ç –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
- –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –∞–¥–∞–ø—Ç–µ—Ä–∞: ~130MB

**–û–±—É—á–µ–Ω–∏–µ:**

```python
# –§–∞–π–ª: lora.py
training_args = TrainingArguments(
    output_dir="./lora_finetuned",
    per_device_train_batch_size=2,
    num_train_epochs=10,
    fp16=True,
    eval_strategy="steps",
    eval_steps=100,
    save_strategy="steps",
    load_best_model_at_end=True,
    metric_for_best_model="eval_loss"
)
```

**–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –∞–¥–∞–ø—Ç–µ—Ä–æ–≤:**

```python
# –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
base_model = AutoModelForCausalLM.from_pretrained("quantized_model")

# –ó–∞–≥—Ä—É–∑–∫–∞ LoRA –∞–¥–∞–ø—Ç–µ—Ä–∞ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
selected_model = PeftModel.from_pretrained(
    base_model,
    f"{agent_name}/best_model"
)

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –∞–¥–∞–ø—Ç–µ—Ä–æ–º
pipeline = pipeline(
    "text-generation",
    model=selected_model,
    tokenizer=selected_tokenizer,
    max_new_tokens=150,
    temperature=0.1,
    top_p=0.95,
    repetition_penalty=1.1
)
```

#### 4.3. –ü—Ä–æ–º–ø—Ç-–∏–Ω–∂–µ–Ω–µ—Ä–∏–Ω–≥

**–ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç:**
```python
base_instruction = """–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π —Å—Ç—Ä–æ–≥–æ –æ—Ç–≤–µ—á–∞–µ—Ç —Ç–æ–ª—å–∫–æ –Ω–∞
–æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞ –≤ –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ.
–ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–µ—Ç, –æ—Ç–≤–µ—á–∞–π –Ω–∞ –æ–±—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã –∫–∞–∫ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –±–æ—Ç
(–ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è, –ø—Ä–æ—â–∞–Ω–∏—è –∏ —Ç.–¥.)."""
```

**–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞:**

```python
def render_chat_with_context(history, question, context, username):
    messages = [
        {"role": "–°–∏—Å—Ç–µ–º–∞", "content": base_instruction +
         ("\n–ö–æ–Ω—Ç–µ–∫—Å—Ç: " + context if context else "")}
    ]

    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏
    for msg in history:
        messages.append({
            "role": msg.get("username"),
            "content": msg["message"]
        })

    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞
    messages.append({"role": username, "content": question})

    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    prompt = "\n".join([f"{m['role']}: {m['content']}"
                        for m in messages]) + "\nAI-–ø–æ–º–æ—â–Ω–∏–∫:"

    return prompt
```

**–ü—Ä–∏–º–µ—Ä –ø—Ä–æ–º–ø—Ç–∞:**

```
–°–∏—Å—Ç–µ–º–∞: –¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π —Å—Ç—Ä–æ–≥–æ –æ—Ç–≤–µ—á–∞–µ—Ç —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏
–ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞ –≤ –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ.
–ö–æ–Ω—Ç–µ–∫—Å—Ç: –î–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Wi-Fi –æ—Ç–∫—Ä–æ–π—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–µ—Ç–∏, –≤—ã–±–µ—Ä–∏—Ç–µ –¥–æ—Å—Ç—É–ø–Ω—É—é
—Å–µ—Ç—å Wi-Fi, –≤–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–æ–ª—å –∏ –Ω–∞–∂–º–∏—Ç–µ "–ü–æ–¥–∫–ª—é—á–∏—Ç—å".

–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –ö–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å Wi-Fi?
AI-–ø–æ–º–æ—â–Ω–∏–∫:
```

**–ì–µ–Ω–µ—Ä–∞—Ü–∏—è:**
```python
generated = pipeline(prompt)
answer = generated[0]['generated_text'].strip()

# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
sentences = list(sentenize(answer))  # razdel library
first_sentence = sentences[0].text if sentences else answer
```

---

### 5. –û—á–µ—Ä–µ–¥—å –∑–∞–¥–∞—á (Message Queue)

#### 5.1. RabbitMQ

**–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä:** `rabbitmq:5672`

**–û—á–µ—Ä–µ–¥–∏:**

| –û—á–µ—Ä–µ–¥—å | –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å | –ü–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |
|---------|--------------|-------------|------------|
| `ai_requests` | Chat Service | AI Service | –ó–∞–ø—Ä–æ—Å—ã –∫ AI |
| `ai_response` | AI Service | Chat Service | –û—Ç–≤–µ—Ç—ã –æ—Ç AI |
| `db_messages` | Chat Service | Operator Service | –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ |

**–§–æ—Ä–º–∞—Ç —Å–æ–æ–±—â–µ–Ω–∏–π:**

```python
# ai_requests
{
    "chatId": "unique-chat-id",
    "message": "–ö–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –ø—Ä–∏–Ω—Ç–µ—Ä?",
    "username": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å",
    "messageHistory": [
        {"username": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å", "message": "–ü—Ä–∏–≤–µ—Ç"},
        {"answer": "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ!"}
    ]
}

# ai_response
{
    "chatId": "unique-chat-id",
    "answer": "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏–Ω—Ç–µ—Ä–∞ –∫ —Å–µ—Ç–∏...",
    "botUsername": "AI-–ø–æ–º–æ—â–Ω–∏–∫",
    "isManager": false  # true = —ç—Å–∫–∞–ª–∞—Ü–∏—è –∫ –æ–ø–µ—Ä–∞—Ç–æ—Ä—É
}
```

#### 5.2. Consumer –≤ AI Service

```python
def callback(ch, method, properties, body):
    try:
        # –ü–∞—Ä—Å–∏–Ω–≥ —Å–æ–æ–±—â–µ–Ω–∏—è
        data = json.loads(body)
        query = data.get('message', '')
        message_history = data.get('messageHistory', [])
        chat_id = data.get('chatId')

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞
        answer, new_history = process_query(
            query,
            message_history,
            current_username,
            chat_id
        )

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —ç—Å–∫–∞–ª–∞—Ü–∏—é
        is_manager = (answer == "–ó–∞–ø—Ä–æ—Å –ø–µ—Ä–µ–¥–∞–Ω —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É.
                               –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ.")

        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
        response = {
            'chatId': chat_id,
            'answer': answer,
            'botUsername': 'AI-–ø–æ–º–æ—â–Ω–∏–∫',
            'isManager': is_manager
        }

        # –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ ai_response
        ch.basic_publish(
            exchange='',
            routing_key='ai_response',
            body=json.dumps(response)
        )

        # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        ch.basic_ack(delivery_tag=method.delivery_tag)

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞: {e}")
        ch.basic_nack(delivery_tag=method.delivery_tag, requeue=False)

# –ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ –æ—á–µ—Ä–µ–¥—å
channel.basic_consume(queue='ai_requests', on_message_callback=callback)
channel.start_consuming()
```

---

### 6. –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã

#### 6.1. Chat Widget (Frontend)

**–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:** React + Socket.IO

**–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ:**
```javascript
const socket = io('http://localhost:8000', {
  path: '/socket.io',
  transports: ['websocket', 'polling']
});
```

**–û—Å–Ω–æ–≤–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è:**

```javascript
// –ü—Ä–∏—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∫ —á–∞—Ç—É
socket.emit('joinChat', {
  chatId: chatId,
  username: username
});

// –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
socket.emit('sendMessage', {
  chatId: chatId,
  message: message,
  username: username
});

// –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
socket.on('message', (data) => {
  appendMessage(data.username, data.message);
});

// –ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏
socket.on('messageHistory', (messages) => {
  renderHistory(messages);
});
```

#### 6.2. Chat Service (Backend)

**–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:** NestJS + Socket.IO

**Gateway:**
```typescript
@WebSocketGateway({
  cors: { origin: '*' }
})
export class ChatGateway {
  @SubscribeMessage('sendMessage')
  async handleMessage(client: Socket, payload: any) {
    const { chatId, message, username } = payload;

    // –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Redis
    await this.redisService.saveMessage(chatId, {
      username,
      message,
      timestamp: new Date()
    });

    // –ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏
    const history = await this.redisService.getHistory(chatId);

    // –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ RabbitMQ
    await this.rabbitmqService.publishToAI({
      chatId,
      message,
      username,
      messageHistory: history
    });

    // Broadcast –≤ –∫–æ–º–Ω–∞—Ç—É
    this.server.to(chatId).emit('message', {
      chatId,
      message,
      username,
      timestamp: new Date()
    });
  }

  @SubscribeMessage('joinChat')
  handleJoinChat(client: Socket, payload: any) {
    const { chatId } = payload;
    client.join(chatId);

    // –û—Ç–ø—Ä–∞–≤–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏
    const history = await this.redisService.getHistory(chatId);
    client.emit('messageHistory', history);
  }
}
```

#### 6.3. Redis Service

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ:** –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞

```typescript
export class RedisService {
  async saveMessage(chatId: string, message: any) {
    const key = `chat:${chatId}:messages`;
    await this.redis.rpush(key, JSON.stringify(message));
    await this.redis.ltrim(key, -50, -1);  // –•—Ä–∞–Ω–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ 50
  }

  async getHistory(chatId: string): Promise<any[]> {
    const key = `chat:${chatId}:messages`;
    const messages = await this.redis.lrange(key, 0, -1);
    return messages.map(m => JSON.parse(m));
  }
}
```

---

## üîÑ –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞

```mermaid
sequenceDiagram
    participant U as üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
    participant W as Chat Widget
    participant K as Kong Gateway
    participant C as Chat Service
    participant Red as Redis
    participant R as RabbitMQ
    participant AI as AI Service
    participant AS as Agent Selector
    participant RAG as RAG Pipeline
    participant Ch as ChromaDB
    participant LLM as Qwen2 + LoRA

    U->>W: –í–≤–æ–¥: "–ù–µ —Ä–∞–±–æ—Ç–∞–µ—Ç Wi-Fi"
    W->>K: WebSocket: sendMessage
    K->>C: Proxy
    C->>Red: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
    C->>R: –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ ai_requests
    C-->>W: –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
    W-->>U: –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è

    R->>AI: –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–∑ –æ—á–µ—Ä–µ–¥–∏
    AI->>AI: –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ (–ø—Ä–æ–≤–µ—Ä–∫–∏)
    AI->>AS: –í—ã–±–æ—Ä –∞–≥–µ–Ω—Ç–∞
    AS->>AS: Embedding similarity
    AS-->>AI: –ê–≥–µ–Ω—Ç "–°–µ—Ç—å" (sim=0.89)

    AI->>RAG: –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    RAG->>Ch: Query embeddings
    Ch-->>RAG: Top-1 –ø–∞—Ä–∞–≥—Ä–∞—Ñ (sim=0.76)
    RAG-->>AI: –ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞–π–¥–µ–Ω

    AI->>AI: –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞–º–∏
    AI->>AI: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞
    AI->>LLM: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å LoRA "–°–µ—Ç—å"
    LLM-->>AI: –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç

    AI->>AI: –í–∞–ª–∏–¥–∞—Ü–∏—è (sim=0.68 > 0.5)
    AI->>AI: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    AI->>R: –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ ai_response

    R->>C: –ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
    C->>Red: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
    C->>W: WebSocket: message
    W->>U: –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ: "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–æ—É—Ç–µ—Ä..."
```

---

## üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã

### –†–∞–∑–º–µ—Ä—ã –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –†–∞–∑–º–µ—Ä | –¢–∏–ø |
|-----------|--------|-----|
| –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å Qwen2-7B (4-bit) | ~4GB | Model weights |
| LoRA –∞–¥–∞–ø—Ç–µ—Ä (1 —à—Ç) | ~130MB | Adapter weights |
| Embedding –º–æ–¥–µ–ª—å (frida) | ~420MB | Model weights |
| –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π (5 —Ñ–∞–π–ª–æ–≤) | ~250KB | Text files |
| Embeddings –≤ ChromaDB | ~20MB | Vector DB |
| Docker images (–æ–±—â–∏–π) | ~15GB | Containers |

### –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ | –£—Å–ª–æ–≤–∏—è |
|---------|----------|---------|
| –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ (avg) | 2-5 —Å–µ–∫—É–Ω–¥ | GPU inference |
| –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ (avg) | 15-30 —Å–µ–∫—É–Ω–¥ | CPU inference |
| Throughput | ~10 req/min | Single GPU |
| Latency (embedding) | ~50ms | Batch size 1 |
| Latency (generation) | 1-4 —Å–µ–∫ | max_tokens=150 |

### –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ä–µ—Å—É—Ä—Å–∞–º

**–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ (CPU):**
- RAM: 16GB
- Disk: 30GB
- CPU: 4 cores

**–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ (GPU):**
- RAM: 16GB
- Disk: 50GB
- GPU: 8GB VRAM (NVIDIA)
- CPU: 8 cores

---

## üéì –ö–ª—é—á–µ–≤—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏

### AI/ML Stack
- **PyTorch** - Deep learning framework
- **Transformers** - Hugging Face –±–∏–±–ª–∏–æ—Ç–µ–∫–∞
- **PEFT** - Parameter-Efficient Fine-Tuning (LoRA)
- **Sentence-Transformers** - Embedding models
- **LangChain** - RAG framework
- **ChromaDB** - Vector database

### Backend Stack
- **Python 3.9+** - AI Service
- **NestJS** - Chat Service
- **Go (Fiber)** - Operator Service
- **RabbitMQ** - Message broker
- **Redis** - Cache
- **PostgreSQL** - Relational DB

### Infrastructure
- **Docker Compose** - Orchestration
- **Kong** - API Gateway
- **Prometheus** - Metrics
- **Grafana** - Visualization
- **Loki** - Logging

---

**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** 2024-10-18
